I am experiencing data accuracy issues after refactoring to the `intel_events` view. I suspect the frontend is silently filtering out valid rows or mapping columns incorrectly.

I need you to completely rewrite the `loadAllData` data fetching logic in `dashboard.js` with a focus on **DATA INTEGRITY** and **DEBUGGING**.

### 1. THE DATA SOURCE (Single Source of Truth)
You must ONLY query the `intel_events` view. Do not query the old tables.
The view now contains a `company_key` column, so you must **STOP** using the old `!inner` join syntax.

### 2. STRICT REQUIREMENTS

**A. NO Hidden Filters:**
- Remove any logic that checks `if (data.length > 0)`.
- Remove any client-side filtering (like `.filter(item => item.image)`). If the data exists in the DB, it MUST reach the UI.
- Use simple Supabase filters:
  - `.eq('source_table', 'facebook_ads')` (etc)
  - `.eq('company_key', filters.company)`
  - `.gte('created_at', filters.dateFrom)`
  - `.lte('created_at', filters.dateTo)`

**B. Data Mapping (Fix the Inaccuracy):**
You must map the fields exactly as follows to match the legacy UI:
- **Facebook:**
  - `start_date_string` = `row.created_at`
  - `page_name` = `row.headline`
  - `ad_text` = `row.description`
  - `ad_image_url` = `row.image_url` (Pass null if missing, do not filter out!)
- **Google:**
  - `first_show` = `row.created_at`
  - `handle` = `row.headline`
  - `format` = `row.description`
- **Instagram:**
  - `created_at` = `row.created_at`
  - `username` = `row.headline`
  - `text` = `row.description`
  - `display_url` = `row.image_url`

**C. Debug Logging (Mandatory):**
Inside `loadFacebookAds` (and others), adds logs BEFORE and AFTER the fetch:
- `console.log('Fetching Facebook Ads with filters:', filters);`
- `console.log('Supabase Response:', { count: data?.length, error });`
- This is critical so I can compare the DB count to the Dashboard count.

### 3. EXECUTION
Rewrite `loadFacebookAds`, `loadGoogleAds`, and `loadInstagramPosts` to follow this strict "Pass-Through" pattern. 
Ensure `updateTableUI` receives the raw mapped data without any items being dropped.

Proceed with the code generation.